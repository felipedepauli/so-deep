<style>
* {
    margin: 0;
    padding: 0;
    box-sizing: border-box;
    text-align: justify;
    /* background-color: #fafafa; */
    /* color: black; */
}
h1, h2, h3 {
    font-family: Poppins;
}
p, div, ol, ul  {
    font-family: "Poppins", "Roboto Condensed";
    text-align: justify;
}
</style>


# Capítulo 4: Introdução às Redes Neurais Artificiais

## Seção 4.1: Introdução às Redes Neurais Artificiais

Nesta seção, será introduzida a ideia das redes neurais artificiais, ou ANNs (Artificial Neural Networks) em inglês. Em particular, discutiremos um tipo específico de rede neural conhecida como rede neural feedforward. Embora seja o tipo mais básico de rede neural, veremos que os conceitos envolvidos são bastante profundos e formam a base para outros tipos de redes neurais, como as redes neurais convolucionais e as redes neurais recorrentes.

### Origens das Redes Neurais

Iniciaremos com uma discussão sobre por que e como as redes neurais surgiram. Muitos educadores optam por não abordar esse tópico, mas é uma história que considero bastante interessante e inspiradora. Se você acha que as redes neurais são apenas um modelo legal para ajudá-lo a escolher ações ou jogar Mario Kart, então ainda está buscando peixes pequenos. Na verdade, as redes neurais são muito mais interessantes que isso.

### O Que é uma Rede Neural?

A denominação "rede neural artificial" sugere que estamos tentando criar uma rede neural em um computador. Mas, então, o que seria uma rede neural não artificial? O termo "rede neural" deriva de neurônios, que são as células no seu cérebro e se estendem por todo o seu sistema nervoso.

Talvez seja óbvio para muitos, mas vale a pena mencionar: seu cérebro é utilizado para pensar. Os neurônios em seu cérebro estão conectados uns aos outros e podem comunicar-se através de sinais elétricos e químicos. Incrivelmente, esse sistema físico e químico simples é o que faz você ser você. Todos os seus pensamentos e aspirações, suas emoções e cada ação que você realiza durante o dia são impulsionados por seus neurônios, que por sua vez estão apenas enviando sinais elétricos e químicos entre si.

### Podemos Construir um Cérebro?

Uma vez que os cientistas entenderam o que o cérebro estava fazendo e qual era sua função, a próxima pergunta foi quase óbvia. Em retrospecto, podemos construir um cérebro? Se o cérebro é apenas uma rede de neurônios e podemos simular neurônios em um computador, se conectarmos um grupo de neurônios através de uma simulação computacional, parece possível criar alguma forma de inteligência, uma inteligência artificial, você poderia dizer.

### Modelando Neurônios

Vamos tomar nosso modelo de um único neurônio — a regressão logística. Agora imagine que temos múltiplos neurônios, todos recebendo as mesmas entradas, mas calculando algo diferente. Agora vamos repetir o processo. Agora temos múltiplas regressões logísticas. Imagine que todos esses neurônios estão conectados a mais neurônios. Então, repetimos o processo, fingindo que a nova camada de neurônios são na verdade entradas para mais neurônios.

Claro, isso é necessariamente simplista. Um lado é a entrada e o outro lado é a saída. Claro, o cérebro real é muito mais complexo. Existem muitas entradas e muitas saídas no meio. Fios podem cruzar-se. Se tivermos um neurônio mais tarde conectando-se de volta a um neurônio anterior, chamamos isso de uma conexão recorrente. As redes neurais que discutiremos nesta seção não contêm tais complexidades internas, porque a entrada está de um lado e a saída do outro lado e vamos de entrada para saída de maneira camada por camada. Chamamos isso de rede neural feedforward.

### Estrutura do Curso

No restante desta palestra, vamos delinear o que discutiremos nesta seção do curso. Primeiramente, começaremos novamente discutindo **a arquitetura do modelo**. Como você sabe, o modelo que discutiremos nesta seção é a rede neural feedforward. O próximo passo após discutir a arquitetura do modelo será voltar à imagem geométrica. Se você se lembra, meu modelo de aprendizado de máquina é nada mais do que um problema de geometria.

### Funções de Ativação e Classificação Multi-classe

A seguir, vamos aprofundar e discutir funções de ativação. As funções de ativação são muito importantes em redes neurais. Elas são o que tornam as redes neurais mais expressivas do que os modelos lineares simples que você viu na seção anterior. Depois disso, vamos discutir como fazer classificação multi-classe usando redes neurais. Se você se lembra, na seção anterior discutimos apenas classificação binária.

### Dados Não Estruturados e Classificação de Imagens

Em seguida, mudaremos de foco, falando sobre a própria rede neural para um novo tipo de dados: imagens. A aprendizagem profunda se destaca em dados não estruturados, como imagens, textos e sons. Examinaremos como as imagens são representadas em um computador para que possamos voltar à situação onde podemos dizer que todos os dados são os mesmos. Por fim, vamos olhar para alguns notebooks que demonstram como fazer classificação de imagens usando uma rede neural para múltiplas classes. Também veremos redes neurais para regressão e veremos como elas podem ser muito mais expressivas do que um modelo linear simples.


## Seção 4.2: Propagação Direta

Nesta seção, exploraremos o conceito de propagação direta em redes neurais, o mecanismo essencial pelo qual as redes neurais fazem previsões. A propagação direta, ou *forward propagation*, refere-se ao processo de avançar do início ao fim da rede, calculando a saída a partir das entradas fornecidas.

### Expansão do Modelo de Neurônio

No contexto de redes neurais, começamos com o modelo de um único neurônio, que já discutimos na forma de regressão logística. Agora, imagine que não temos apenas um, mas múltiplos neurônios recebendo as mesmas entradas. Cada neurônio pode estar focado em detectar características diferentes da entrada. Por exemplo, um neurônio pode estar configurado para detectar a presença de um olho, enquanto outro pode estar focado em identificar um nariz. 

### Arquitetura de Múltiplos Neurônios

Agora, imagine adicionar mais neurônios e formar uma camada completa de neurônios. A ideia revolucionária no campo do aprendizado profundo, proposta por pesquisadores como Geoffrey Hinton, era que poderíamos empilhar camadas de neurônios umas sobre as outras, imitando de certa forma a complexidade do cérebro humano, que possui não apenas um, mas bilhões de neurônios interconectados.

### Conceito de Redes Neurais Amplas e Profundas

Essencialmente, ampliamos a rede neural adicionando mais neurônios em uma camada (tornando-a mais "ampla") e aprofundamos a rede adicionando mais camadas de neurônios (tornando-a mais "profunda"). Esta abordagem é a base para construir uma rede neural eficaz: começar com um neurônio, expandir para uma camada de múltiplos neurônios e, em seguida, adicionar camadas sucessivas.

### Modelo Matemático da Propagação Direta

No modelo matemático da propagação direta, consideramos a equação para uma linha como nosso modelo inicial, que se transforma quando adicionamos múltiplas entradas e pesos. Introduzimos a função sigmoide no final para mapear a saída para um valor entre zero e um, que pode representar algo como a probabilidade de um evento. Quando expandimos para múltiplos neurônios por camada, o cálculo se torna um pouco mais complexo.

Suponha que temos várias saídas na próxima camada. Podemos então considerar que cada saída de um neurônio em uma camada é influenciada pelos pesos e pelo viés da camada anterior, seguido pela aplicação de uma função de ativação, como a sigmoide.

### Implementação com Matrizes

No contexto matricial, podemos representar as operações de uma rede neural de forma mais compacta. Cada camada de neurônios pode ser descrita por uma matriz de pesos e um vetor de viés. A multiplicação de matrizes nos permite calcular as saídas para toda uma camada de neurônios de uma só vez, o que é crucial para a eficiência computacional.

### Hierarquia de Aprendizado em Redes Neurais Profundas

Usando essas camadas uniformes, percebeu-se que as redes neurais eram capazes de aprender hierarquias de recursos, com cada camada aprendendo características progressivamente mais complexas. Esta capacidade de decompor problemas em subproblemas menores é fundamental para o sucesso do aprendizado profundo em tarefas complexas, como o reconhecimento facial, onde camadas iniciais aprendem traços básicos e camadas mais profundas conseguem reconhecer características faciais completas.

Essa abordagem de camadas sucessivas transforma a rede neural não apenas em um modelo de classificação ou regressão, mas em uma poderosa ferramenta de transformação de características, aprendendo representações cada vez mais sofisticadas dos dados de entrada. Assim, as redes neurais não apenas imitam a regressão linear e logística em suas camadas finais, mas expandem essas técnicas para modelar complexidades que esses métodos mais simples não podem capturar sozinhos.

## Seção 4.3: A Imagem Geométrica

Neste ponto, você provavelmente já está cansado de me ouvir dizer que aprendizado de máquina é essencialmente um problema de geometria. Mas aqui é onde esse conceito se torna realmente importante. A questão que queremos responder agora é: por que as redes neurais são tão importantes? Por que não podemos simplesmente usar um único neurônio? Parece ser um modelo bastante bom e interpretável. Pesos grandes significam que a entrada correspondente é importante e pesos muito pequenos ou nulos significam que a entrada não é importante. Infelizmente, este tipo de modelo tem suas limitações.

### Regressão Linear e Redes Neurais

Você deve se lembrar que, quando discutimos regressão linear e regressão logística, mencionei que existem duas maneiras de complicar as coisas. A primeira maneira é adicionar múltiplas entradas, o que já encontramos. Isso ainda é bastante simplista, porque você sempre pode imaginar um plano na sua cabeça, uma superfície não curva que separa os dados entre classes. A segunda maneira é que a fronteira de decisão ou a função de regressão que estamos procurando não é uma linha reta ou um plano. É isso que nos interessa ao discutirmos redes neurais.

### Superando Limitações com Engenharia de Recursos

A razão pela qual a equação $ W^T x + B = 0 $ nos dá um hiperplano é porque essa é a definição real de um hiperplano. Não há como contornar isso. Não há configuração possível de $ W $ e $ B $ que possa nos dar uma superfície curva. Então, como podemos obter uma superfície curva para resolver problemas mais complicados? Uma maneira que você pode ter pensado é usar engenharia de recursos. Por exemplo, vamos considerar a regressão linear. Suponha que, por qualquer motivo, o salário seja proporcional ao quadrado dos anos de experiência. Ou, dito de outra forma, que o salário é uma função quadrática dos anos de experiência. Então poderíamos dizer que $ \hat{y} = a x^2 + b x + c $. Acredite ou não, isso ainda é apenas regressão linear disfarçada.

### Simplificação com Redes Neurais

É fácil ver isso pegando $ x $, os anos de experiência, e chamando isso de recurso de entrada $ x_1 $. Então pegue $ x^2 $, os anos de experiência ao quadrado, e chame isso de recurso de entrada $ x_2 $. Então, meu $ \hat{y} $ se torna uma equação do tipo $ \hat{y} = W_1X_1 + W_2X_2 + b $. Claro, já aprendemos que isso é apenas uma regressão linear. O problema com a engenharia de recursos é que existem muitos recursos possíveis. Elevar ao quadrado as entradas é comum, mas também é combinar as entradas. Então, se eu tenho as entradas $ x_1 $ e $ x_2 $, então posso fazer um dos recursos $ x_1 \times x_2 $.

### Neurônios como Recursos Não-Lineares

Mas agora vamos lembrar do nosso neurônio. Se considerarmos apenas a primeira camada de uma rede neural, podemos ver que existem múltiplos neurônios. Importante, são todos neurônios diferentes. Cada neurônio é uma característica não-linear diferente derivada de todas as entradas porque aplicamos a função de ativação sigmoide. A característica não é apenas uma combinação linear simples das características de entrada, então você pode pensar nesses como recurso um, recurso dois, recurso três, até o recurso $ m $.

### Implicações da Não-Linearidade

Lembre-se de que uma função linear sempre toma a forma $( W^T x + B )$. Nossa rede neural toma a forma da equação que você vê aqui para uma rede neural de duas camadas. Isso é o que obtemos se eliminarmos o termo $ Z $ e transformarmos tudo em uma equação única. $ W_2^T \text{sigmoid}(W_1^T x + B_1) + B_2 $. A coisa importante a notar sobre isso é que você não pode simplificar isso para uma função linear. Se pudesse, então teríamos uma fronteira de decisão linear.

### Redes Neurais na Prática

Portanto, se você nunca teve que criar manualmente coisas como essa, considere-se sortudo. Por padrão, temos uma rede neural com duas camadas ocultas com quatro unidades ocultas. Então, vamos apenas executar isso e ver o que acontece. Conforme você pode ver, ela aprende a fronteira de decisão linear de forma bastante eficiente sem a necessidade de qualquer engenharia de recursos manual. Você é encorajado a brincar com isso por conta própria. Então tente mudar os conjuntos de dados para que você possa escolher, digamos, este e então executá-lo novamente. Também tente diferentes números de camadas ocultas e diferentes números de unidades por camada oculta. Isso deve ajudar a dar uma intuição mais forte sobre como as redes neurais funcionam e permitir que você observe por si mesmo que elas estão encontrando fronteiras de decisão não-lineares.

## Seção 4.4: Funções de Ativação em Redes Neurais

Nesta palestra, vamos discutir as funções de ativação, que são cruciais para as redes neurais. Aprendemos anteriormente que a função sigmoidal nos permite construir redes neurais por ser uma função não-linear que mapeia suas entradas de 0 a 1. Isso é benéfico porque imita o neurônio biológico e impede que a rede seja simplificada em uma equação linear simples.

### Limitações da Sigmóide

No entanto, no aprendizado profundo moderno, descobrimos problemas com a sigmoidal, sendo assim, ela não é mais usada com tanta frequência, exceto em casos específicos. Um dos problemas é que a saída da sigmoidal nunca está centralizada em torno de zero, o que é problemático para a padronização dos dados, algo essencial em aprendizado de máquina.

### Tanh como Alternativa

Como solução, em vez de usar a sigmoidal, podemos usar uma função que possui a mesma forma, mas centralizada em torno de zero. Essa função é a tangente hiperbólica (tanh), que varia de -1 a 1. Assim como a sigmoidal, a tanh também sofre do problema do gradiente desaparecendo em redes profundas, o que pode dificultar o treinamento em camadas anteriores devido à multiplicação repetida de gradientes pequenos, levando a um gradiente praticamente nulo.

### O Problema do Gradiente Desaparecido

Esse fenômeno é conhecido como o problema do gradiente desaparecido. À medida que o gradiente é propagado para trás através da rede, ele diminui exponencialmente, o que torna o ajuste dos pesos nas primeiras camadas quase ineficaz. Historicamente, isso limitava a profundidade das redes neurais que poderiam ser treinadas eficazmente.

### Soluções Históricas e Modernas

Historicamente, uma solução era o treinamento guloso camada por camada, uma técnica desenvolvida por Geoffrey Hinton. Essa abordagem envolvia treinar cada camada individualmente antes de proceder para a próxima. No entanto, hoje em dia, essa abordagem foi em grande parte substituída pelo uso de funções de ativação que não sofrem do problema do gradiente desaparecido.

### ReLU e Suas Variantes

Uma dessas funções é a unidade linear retificada (ReLU), que apesar de simples, resolve muitos desses problemas ao permitir que o gradiente seja transmitido de forma eficaz, exceto quando o neurônio está inativo (o que pode levar a neurônios "mortos"). Variações da ReLU, como a Leaky ReLU e a ELU (Exponential Linear Unit), tentam resolver esse problema permitindo pequenos gradientes negativos, o que ajuda a manter os neurônios "ativos" durante o treinamento.

### Importância da Experimentação

Apesar da teoria e das variações propostas, a ReLU continua sendo uma escolha padrão devido à sua eficácia e simplicidade. O aprendizado de máquina é uma área altamente experimental, e frequentemente uma abordagem simples pode superar uma mais complexa, dependendo do contexto específico da tarefa. Portanto, a experimentação continua sendo um componente crucial no desenvolvimento de modelos de aprendizado de máquina.

### Considerações Biológicas

Curiosamente, a ReLU pode ser mais plausivelmente biológica do que a sigmoidal. Na biologia, a frequência dos potenciais de ação (ou seja, a frequência com que os neurônios disparam) codifica a intensidade do estímulo, não a magnitude dos potenciais de ação individuais, o que se assemelha mais à função de ativação da ReLU do que às funções tradicionais como a sigmoidal.

## Conclusão

As funções de ativação são fundamentais para o sucesso das redes neurais, permitindo-lhes aprender e modelar complexidades não-linearidades dos dados. A escolha da função de ativação pode ter um impacto significativo no desempenho da rede, e a experimentação continua sendo uma ferramenta essencial para encontrar a função ideal para um dado problema.

## Seção 4.4: Funções de Ativação em Redes Neurais

Nesta palestra, vamos discutir as funções de ativação, que são cruciais para as redes neurais. Aprendemos anteriormente que a função sigmoidal nos permite construir redes neurais por ser uma função não-linear que mapeia suas entradas de 0 a 1. Isso é benéfico porque imita o neurônio biológico e impede que a rede seja simplificada em uma equação linear simples.

### Limitações da Sigmóide

No entanto, no aprendizado profundo moderno, descobrimos problemas com a sigmoidal, sendo assim, ela não é mais usada com tanta frequência, exceto em casos específicos. Um dos problemas é que a saída da sigmoidal nunca está **centralizada em torno de zero**, o que é problemático para a padronização dos dados, algo essencial em aprendizado de máquina.

### Tanh como Alternativa

Como solução, em vez de usar a sigmoidal, podemos usar uma função que possui a mesma forma, mas centralizada em torno de zero. Essa função é a tangente hiperbólica (tanh), que varia de -1 a 1. Assim como a sigmoidal, a tanh também sofre do problema do gradiente desaparecendo em redes profundas, o que pode dificultar o treinamento em camadas anteriores devido à multiplicação repetida de gradientes pequenos, levando a um gradiente praticamente nulo.

### O Problema do Gradiente Desaparecido

Esse fenômeno é conhecido como o problema do gradiente desaparecido. À medida que o gradiente é propagado para trás através da rede, ele diminui exponencialmente, o que torna o ajuste dos pesos nas primeiras camadas quase ineficaz. Historicamente, isso limitava a profundidade das redes neurais que poderiam ser treinadas eficazmente.

### Soluções Históricas e Modernas

Historicamente, uma solução era o treinamento guloso camada por camada, uma técnica desenvolvida por Geoffrey Hinton. Essa abordagem envolvia treinar cada camada individualmente antes de proceder para a próxima. No entanto, hoje em dia, essa abordagem foi em grande parte substituída pelo uso de funções de ativação que não sofrem do problema do gradiente desaparecido.

### ReLU e Suas Variantes

Uma dessas funções é a unidade linear retificada (ReLU), que apesar de simples, resolve muitos desses problemas ao permitir que o gradiente seja transmitido de forma eficaz, exceto quando o neurônio está inativo (o que pode levar a neurônios "mortos"). Variações da ReLU, como a Leaky ReLU e a ELU (Exponential Linear Unit), tentam resolver esse problema permitindo pequenos gradientes negativos, o que ajuda a manter os neurônios "ativos" durante o treinamento.

### Importância da Experimentação

Apesar da teoria e das variações propostas, a ReLU continua sendo uma escolha padrão devido à sua eficácia e simplicidade. O aprendizado de máquina é uma área altamente experimental, e frequentemente uma abordagem simples pode superar uma mais complexa, dependendo do contexto específico da tarefa. Portanto, a experimentação continua sendo um componente crucial no desenvolvimento de modelos de aprendizado de máquina.

### Considerações Biológicas

Curiosamente, a ReLU pode ser mais plausivelmente biológica do que a sigmoidal. Na biologia, a frequência dos potenciais de ação (ou seja, a frequência com que os neurônios disparam) codifica a intensidade do estímulo, não a magnitude dos potenciais de ação individuais, o que se assemelha mais à função de ativação da ReLU do que às funções tradicionais como a sigmoidal.

### Razões para Usar Funções de Ativação

**Introduzir Não-Linearidade:** A maioria dos fenômenos do mundo real não é linear por natureza. Sem não-linearidade, uma rede neural com muitas camadas seria teoricamente equivalente a uma rede de uma única camada, pois somar múltiplas funções lineares resulta em outra função linear. As funções de ativação não-lineares permitem que a rede aprenda padrões mais complexos, como curvas e classificações não-lineares, que são comuns em problemas reais, como reconhecimento de imagem e processamento de linguagem natural.  
**Modelar Relações Complexas:** Ao adicionar uma função de ativação, cada neurônio pode aprender a decidir o quão "ativado" ele deve estar em resposta a um conjunto de entradas. Essa "decisão" é baseada na saída da função de ativação, que determina se e quanto um sinal contribuirá para a próxima camada. Isso permite que a rede neural modele relações complexas entre as características dos dados.  
**Controlar a Amplitude da Saída:** Funções de ativação como a sigmoid e a tanh têm saídas limitadas (por exemplo, entre 0 e 1 para a sigmoid e entre -1 e 1 para a tanh). Isso ajuda a manter as saídas da rede dentro de um intervalo controlado, o que pode ser útil para certas aplicações como modelar probabilidades.

## Conclusão

As funções de ativação são fundamentais para o sucesso das redes neurais, permitindo-lhes aprender e modelar complexidades não-linearidades dos dados. A escolha da função de ativação pode ter um impacto significativo no desempenho da rede, e a experimentação continua sendo uma ferramenta essencial para encontrar a função ideal para um dado problema.

## Seção 4.5: Introdução à Classificação Multiclasse

Nesta seção, abordaremos um tópico essencial no aprendizado profundo: a classificação multiclasse. Já discutimos a classificação binária, onde um neurônio de saída com função de ativação sigmoide é típico. Porém, em muitos cenários práticos, precisamos lidar com mais de duas categorias possíveis, o que exige uma abordagem diferente.

### Limitações da Classificação Binária

A classificação binária é eficaz quando as previsões se enquadram em uma de duas categorias, como "fraudulento" ou "não fraudulento" e "clicará no anúncio" ou "não clicará". Contudo, muitas aplicações exigem a identificação entre várias categorias. Por exemplo:

- **Reconhecimento Óptico de Caracteres**: Podemos ter 36 categorias potenciais (10 dígitos e 26 letras).
- **Reconhecimento de Fala**: Cada palavra pode ser considerada uma categoria separada.
- **Classificação de Imagem**: Pode haver centenas ou mesmo milhares de categorias, como demonstrado pelo famoso conjunto de dados ImageNet.

### Como Funciona a Classificação Multiclasse?

Em redes neurais destinadas à classificação multiclasse, a camada de saída possui múltiplos neurônios, cada um representando uma categoria. A função de ativação usada aqui é crucial para mapear os valores da última camada linear da rede em probabilidades que somam um, adequadas para representar múltiplas classes.

#### A Função Softmax

A função softmax é ideal para este propósito. Ela converte um vetor de valores para um vetor de probabilidades, com cada componente representando a probabilidade de uma das classes. A equação da função softmax para um vetor $A$ de tamanho $K$ é:

$$ \text{Softmax}(A_i) = \frac{e^{A_i}}{\sum_{k=1}^K e^{A_k}} $$

onde $A_i$ é o valor de ativação para a classe $i$ e o denominador é a soma das exponenciais de todos os valores de ativação, garantindo que as saídas somem um.

### Implementação da Softmax

Em frameworks de aprendizado profundo, como TensorFlow, a função softmax é geralmente aplicada automaticamente como parte da camada de saída para tarefas de classificação multiclasse. A implementação é direta: você especifica `softmax` como a função de ativação na última camada da sua rede.

### Uso Prático e Limitações

Embora o softmax seja comumente usado apenas na camada de saída, teoricamente, ele poderia ser utilizado nas camadas ocultas. No entanto, isso é raro e geralmente não é eficaz, pois o softmax na camada oculta pode levar a gradientes extremamente pequenos, o que pode complicar o processo de aprendizado da rede.

### Tipos de Tarefas e Funções de Ativação Correspondentes

Vimos três configurações principais de tarefas e suas funções de ativação:
- **Regressão**: Nenhuma função de ativação específica, ou função de identidade.
- **Classificação Binária**: Sigmóide.
- **Classificação Multiclasse**: Softmax.

Importante destacar que independentemente da arquitetura do modelo (CNN, RNN, etc.), a escolha da função de ativação para a camada de saída deve alinhar-se com o tipo de tarefa a ser realizada.

### Conclusão

O entendimento das funções de ativação e a correta implementação da softmax são fundamentais para o sucesso em tarefas de classificação multiclasse. Esta abordagem não apenas amplia o alcance das aplicações possíveis para redes neurais, mas também destaca a flexibilidade e a capacidade desses modelos de adaptar-se a uma variedade de problemas complexos.

